{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyNoV2PV0hO65lcm3MmVotVc",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": "# Лекция 2.3. Задача классификации"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Задание"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Перебрать препроцессоры для тех же самых моделей:\n",
    "\n",
    "1. Normalizer\n",
    "2. MaxAbsScaler\n",
    "3. Без нормировки\n",
    "\n",
    "Зафиксировать F1 score на тестовой выборке. Выбрать наилучшую модель."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T04:41:11.630346Z",
     "start_time": "2025-10-06T04:41:11.201461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# подключим библиотеки\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# подключим необходимые функции\n",
    "from sklearn.model_selection import train_test_split  # деление выборки на обучающую и тестовую\n",
    "from sklearn.preprocessing import StandardScaler  # нормализация (Z-стандартизация)\n",
    "\n",
    "# алгоритмы классификации\n",
    "from sklearn.linear_model import LogisticRegression  # логистическая регрессия\n",
    "from sklearn.neighbors import KNeighborsClassifier  # kNN для классификации\n",
    "from sklearn.tree import DecisionTreeClassifier  # дерево решений для классификации\n",
    "from sklearn.svm import SVC  # метод опорных векторов для классификации\n",
    "from sklearn.naive_bayes import GaussianNB  # наивный Байес для нормально распределенных факторных признаков\n",
    "from sklearn.dummy import DummyClassifier # тривиальный классификатор\n",
    "\n",
    "from sklearn import metrics  # функции для расчета показателей качества моделей\n",
    "\n",
    "# загрузим данные по прямой ссылке из CSV-файла\n",
    "df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/rvgarafutdinov/python_book_2023/main/apartments2.csv\",\n",
    ")\n",
    "\n",
    "X_cols = list(df.columns[3:])  # отберем все признаки, кроме первого (он целевой)\n",
    "\n",
    "# целевой признак - новостройка или нет\n",
    "y_col = \"new\"\n",
    "\n",
    "# разобьем выборку на обучающую и тестовую в соотношении 8 к 2\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  df[X_cols], df[y_col], test_size=0.2, random_state=17\n",
    ")\n",
    "\n",
    "# проверим сбалансированность значений целевого признака в обучающей и тестовой выборках\n",
    "y_train.value_counts(normalize=True)\n",
    "y_test.value_counts(normalize=True)\n",
    "\n",
    "# нормализованные данные поместим не в NumPy-массив, а в датафрейм\n",
    "# (ниже будет объяснено, почему сделали так)\n",
    "\n",
    "X_train_norm = X_train.copy()  # создадим копию обучающего датафрейма\n",
    "\n",
    "scaler = StandardScaler()  # создадим объект для нормализации (нормализатор)\n",
    "scaler.fit(X_train[X_cols[:-6]])  # \"обучим\" наш нормализатор на обучающей выборке,\n",
    "# при этом фиктивные переменные (последние 6 столбцов) в нормализацию не включаем, они и так 0 и 1\n",
    "X_train_norm[X_cols[:-6]] = scaler.transform(X_train[X_cols[:-6]])  # нормализуем данные обучающей выборки,\n",
    "\n",
    "\n",
    "# но т.к. результатом является NumPy-массив, перезапишем им столбцы датафрейма,\n",
    "# в итоге получим нормализованный датафрейм\n",
    "# для начала попробуем все 5 алгоритмов с гиперпараметрами по умолчанию\n",
    "# (плюс тривиальный классификатор для сравнения)\n",
    "#\n",
    "# # kNN\n",
    "model_kNN = KNeighborsClassifier()  # k (число ближайших соседей) по умолчанию 5\n",
    "model_kNN.fit(X=X_train_norm, y=y_train)\n",
    "#\n",
    "# # логистическая регрессия\n",
    "model_logit = LogisticRegression()\n",
    "model_logit.fit(X=X_train_norm, y=y_train)\n",
    "#\n",
    "# # машины опорных векторов\n",
    "model_SVC = SVC()\n",
    "model_SVC.fit(X=X_train_norm, y=y_train)\n",
    "#\n",
    "# # дерево решений\n",
    "model_tree = DecisionTreeClassifier()\n",
    "model_tree.fit(X=X_train_norm, y=y_train)\n",
    "#\n",
    "# # наивный Байес\n",
    "model_bayes = GaussianNB()\n",
    "model_bayes.fit(X=X_train_norm, y=y_train)\n",
    "#\n",
    "# # тривиальный классификатор\n",
    "model_dummy = DummyClassifier()\n",
    "model_dummy.fit(X=X_train_norm, y=y_train);"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/v.khlebalov/PycharmProjects/colab/.venv/lib/python3.9/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/v.khlebalov/PycharmProjects/colab/.venv/lib/python3.9/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/v.khlebalov/PycharmProjects/colab/.venv/lib/python3.9/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/v.khlebalov/PycharmProjects/colab/.venv/lib/python3.9/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/v.khlebalov/PycharmProjects/colab/.venv/lib/python3.9/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/v.khlebalov/PycharmProjects/colab/.venv/lib/python3.9/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  }
 ]
}
